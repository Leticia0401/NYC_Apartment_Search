{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 downloading, cleaning & flitering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url, file_name, force=False):\n",
    "    filename = Path(file_name + '.geojson')\n",
    "    \n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {file_name}...\")\n",
    "    \n",
    "        response = requests.get(url)\n",
    "        text = response.text\n",
    "\n",
    "        with open(file_name + '.geojson', 'w') as file:\n",
    "            file.write(text)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Reading from {file_name}...\")\n",
    "    \n",
    "    gdf = gpd.read_file(file_name + '.geojson', driver = 'GeoJSON')\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data():\n",
    "    url = \"https://data.cityofnewyork.us/resource/erm2-nwe9.geojson?$$app_token=RbFfvU4T8a7C7rDHaA9eqAkvZ\"\n",
    "    file_name = 'complaints_head(1000)'\n",
    "    complaints = download_nyc_geojson_data(url, file_name, force=False)\n",
    "    \n",
    "    # choose columns we neeed\n",
    "    new_complaints = complaints[['created_date', 'incident_zip','complaint_type','geometry']]\n",
    "    \n",
    "    # 去除NaN\n",
    "    columns_with_nan = new_complaints.columns[new_complaints.isnull().any()].tolist()\n",
    "    \n",
    "    for column_name in columns_with_nan:\n",
    "        print(\"Processing column:\", column_name)\n",
    "        new_complaints = new_complaints.dropna(subset=[column_name])\n",
    "        print(\"Removed rows with NaN value in\", column_name)\n",
    "\n",
    "    return new_complaints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    url = \"https://data.cityofnewyork.us/resource/5rq2-4hqu.geojson?$$app_token=RbFfvU4T8a7C7rDHaA9eqAkvZ\"\n",
    "    file_name = 'trees_head(1000)'\n",
    "    trees = download_nyc_geojson_data(url, file_name, force=False)\n",
    "    \n",
    "    # 去除NaN\n",
    "    columns_with_nan = trees.columns[trees.isnull().any()].tolist()\n",
    "    \n",
    "    for column_name in columns_with_nan:\n",
    "        print(\"Processing column:\", column_name)\n",
    "        trees = trees.dropna(subset=[column_name])\n",
    "        print(\"Removed rows with NaN value in\", column_name)\n",
    "        \n",
    "    # choose columns we neeed\n",
    "    new_trees = trees[['tree_id', 'health', 'status', 'latitude', 'longitude', 'geometry']].copy()\n",
    "\n",
    "    return new_trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile):\n",
    "    zipcode_data = gpd.read_file(zipcode_datafile)\n",
    "    \n",
    "    zipcodes = pd.DataFrame(\n",
    "           zipcode_data,\n",
    "           columns=['ZIPCODE', 'geometry'])\n",
    "    # Convert 'Polygon' column to a format supported by SQL\n",
    "    # Replace 'polygon_column' with your actual 'Polygon' column name\n",
    "    ## zipcodes['geometry'] =zipcodes['geometry'].apply(lambda x: x.wkt if x else None)\n",
    "\n",
    "    # Define data types explicitly (required for 'Polygon' column)\n",
    "    ## data_types = {'geometry': String}  # Adjust the data type as per your SQL schema\n",
    "    return zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data(rent_datafile):\n",
    "    zillow_rent_data = pd.read_csv(rent_datafile)\n",
    "    \n",
    "    columns_to_drop = ['RegionID', 'SizeRank','RegionType', 'State','StateName', 'City','Metro','CountyName']\n",
    "    rents = zillow_rent_data.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return rents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"ZIP_CODE_040114.shp\"\n",
    "ZIPCODE_DATA_FILE = 'data/zipcodes/nyc_zipcodes.shp'\n",
    "RENT_DATA_FILE = 'data/zillow_rent_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data(RENT_DATA_FILE)\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
