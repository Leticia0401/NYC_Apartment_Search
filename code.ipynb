{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62c65bb",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import requests\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.animation as animation\n",
    "import unittest\n",
    "\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de69d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants you might need; some have been added for you\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "#DATA_DIR = pathlib.Path(\"data\")\n",
    "#ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"ZIP_CODE_040114.shp\"\n",
    "#ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "ZIPCODE_DATA_FILE = 'data/zipcodes/nyc_zipcodes.shp'\n",
    "RENT_DATA_FILE = 'data/zillow_rent_data.csv'\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"qusZQnQU0ua9VbjGpXFDVhsbK\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"FINAL_PROJECT_DATA\"\n",
    "DB_USER = \"leticialx\"\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d8cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a32a9",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdfc6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_geojson_data(url: str,\n",
    "                              file_name: str, \n",
    "                              force: bool = False) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Download NYC GeoJSON data from a provided URL and saves it to a file.\n",
    "    \n",
    "    Keyword arguments:\n",
    "    url (str) -- the URL from which the GeoJSON data will be downloaded\n",
    "    file_name (str) -- the name of the file (without extension) to save the GeoJSON data\n",
    "    force (bool, optional) -- if True, forces re-download of the file even if it exists locally (default is false)\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = Path(file_name + '.geojson')\n",
    "    \n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {file_name}...\")\n",
    "    \n",
    "        response = requests.get(url)\n",
    "        text = response.text\n",
    "\n",
    "        with open(file_name + '.geojson', 'w') as file:\n",
    "            file.write(text)\n",
    "        print(f\"Done downloading {url}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Reading from {file_name}...\")\n",
    "    \n",
    "    gdf = gpd.read_file(file_name + '.geojson', driver = 'GeoJSON')\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1383098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_311_data() -> gpd.GeoDataFrame:\n",
    "    \"\"\"Download and clean 311 complaints data.\"\"\"\n",
    "    \n",
    "    url = \"https://data.cityofnewyork.us/resource/erm2-nwe9.geojson?$$app_token=RbFfvU4T8a7C7rDHaA9eqAkvZ\"\n",
    "    \n",
    "    file_name = 'complaints_head(10000)'\n",
    "    complaints = download_nyc_geojson_data(url, file_name, force=False)\n",
    "    \n",
    "    # choose the columns we neeed\n",
    "    new_complaints = complaints[['created_date', 'incident_zip', 'complaint_type', 'geometry']]\n",
    "    \n",
    "    # normalize SRID to EPSG:4326\n",
    "    new_complaints = new_complaints.to_crs(epsg=4326)\n",
    "    \n",
    "    # delete NaN\n",
    "    columns_with_nan = new_complaints.columns[new_complaints.isnull().any()].tolist()\n",
    "    \n",
    "    for column_name in columns_with_nan:\n",
    "        print(\"Processing column:\", column_name)\n",
    "        new_complaints = new_complaints.dropna(subset=[column_name])\n",
    "        print(\"Removed rows with NaN value in\", column_name)\n",
    "\n",
    "    return new_complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0242d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data() -> gpd.GeoDataFrame:\n",
    "    \"\"\"Download and clean 2015 tree census data.\"\"\"\n",
    "    \n",
    "    url = \"https://data.cityofnewyork.us/resource/5rq2-4hqu.geojson?$$app_token=RbFfvU4T8a7C7rDHaA9eqAkvZ\"\n",
    "    file_name = 'trees_head(10000)'\n",
    "    trees = download_nyc_geojson_data(url, file_name, force=False)\n",
    "    \n",
    "    # normalize SRID to EPSG:4326\n",
    "    trees = trees.to_crs(epsg=4326)\n",
    "    \n",
    "    # delete NaN\n",
    "    columns_with_nan = trees.columns[trees.isnull().any()].tolist()\n",
    "    \n",
    "    for column_name in columns_with_nan:\n",
    "        print(\"Processing column:\", column_name)\n",
    "        trees = trees.dropna(subset=[column_name])\n",
    "        print(\"Removed rows with NaN value in\", column_name)\n",
    "        \n",
    "    # choose the columns we neeed\n",
    "    new_trees = trees[['tree_id', 'zipcode', 'spc_common', 'health', 'status','geometry']].copy()\n",
    "\n",
    "    return new_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11aac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Load and clean NYC’s zip codes with geometric boundary data data.\"\"\"\n",
    "    \n",
    "    zipcode_data = gpd.read_file(zipcode_datafile)\n",
    "    \n",
    "    zipcodes = zipcode_data[['ZIPCODE', 'geometry']]\n",
    "    zipcodes = zipcodes.rename(columns={'ZIPCODE': 'zipcode'})\n",
    "    \n",
    "    # normalize SRID to EPSG:4326\n",
    "    zipcodes = zipcodes.to_crs(epsg=4326)\n",
    "    \n",
    "    return zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data(rent_datafile: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and clean historical monthly average rents by zip code from Zillow.\"\"\"\n",
    "    \n",
    "    zillow_rent_data = pd.read_csv(rent_datafile)\n",
    "    \n",
    "    columns_to_drop = ['RegionID', 'SizeRank', 'RegionType', 'State', 'StateName', 'City', 'Metro', 'CountyName']\n",
    "    df_zillow_data = zillow_rent_data.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Normalize rent data\n",
    "    df_zillow_data = df_zillow_data.rename(columns={'RegionName': 'rent_zip'})\n",
    "    \n",
    "    rents = pd.melt(df_zillow_data, id_vars=['rent_zip'], var_name='rent_date', value_name='rent_amount')\n",
    "    \n",
    "    rents['rent_date'] = pd.to_datetime(rents['rent_date'])\n",
    "    \n",
    "    # Drop NaNs\n",
    "    rents = rents.dropna()\n",
    "    \n",
    "    return rents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data() -> (gpd.GeoDataFrame, gpd.GeoDataFrame, gpd.GeoDataFrame, pd.DataFrame):\n",
    "    \"\"\"Load all data.\"\"\"\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "    df_zillow_data = load_and_clean_zillow_data(RENT_DATA_FILE)\n",
    "    return (\n",
    "        geodf_zipcode_data,\n",
    "        geodf_311_data,\n",
    "        geodf_tree_data,\n",
    "        df_zillow_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487d7b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6eb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic info about each dataframe\n",
    "geodf_zipcode_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b528574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 entries about each dataframe\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b80d367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geodf_311_data = download_and_clean_311_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588dfead",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geodf_311_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f49871",
   "metadata": {},
   "outputs": [],
   "source": [
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79387491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记得删掉！！\n",
    "tree = gpd.read_file('trees.geojson')\n",
    "trees = tree.to_crs(epsg=4326)\n",
    "\n",
    "# delete NaN\n",
    "columns_with_nan = trees.columns[trees.isnull().any()].tolist()\n",
    "\n",
    "for column_name in columns_with_nan:\n",
    "    print(\"Processing column:\", column_name)\n",
    "    trees = trees.dropna(subset=[column_name])\n",
    "    print(\"Removed rows with NaN value in\", column_name)\n",
    "\n",
    "# choose the columns we neeed\n",
    "geodf_tree_data = trees[['tree_id', 'zipcode', 'spc_common', 'health', 'status','geometry']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72549907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geodf_tree_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a5a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1947a044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5d7dc",
   "metadata": {},
   "source": [
    "# Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a82fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_new_postgis_database(username, db_name):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c925bc8",
   "metadata": {},
   "source": [
    "### Creating Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58ed6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de823605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the SQL statements to create 4 tables using SQL\n",
    "ZIPCODE_SCHEMA = \"\"\"\n",
    "CREATE TABLE nyc_zip_codes (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    zip_code INTEGER,\n",
    "    geom POLYGON\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "NYC_311_SCHEMA = \"\"\"\n",
    "CREATE TABLE complaints_311 (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    created_date TIMESTAMP,\n",
    "    incident_zip INTEGER,\n",
    "    complaints_type TEXT,\n",
    "    geometry POINT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "NYC_TREE_SCHEMA = \"\"\"\n",
    "CREATE TABLE trees (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    tree_id INTEGER,\n",
    "    tree_zip INTEGER,\n",
    "    spc_common TEXT,\n",
    "    health TEXT,\n",
    "    status TEXT,\n",
    "    geometry POINT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "ZILLOW_SCHEMA = \"\"\"\n",
    "CREATE TABLE rents (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    rent_zip INTEGER,\n",
    "    rent_date DATE,\n",
    "    rent NUMERIC(6)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d1e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DB_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(ZIPCODE_SCHEMA)\n",
    "    f.write(NYC_311_SCHEMA)\n",
    "    f.write(NYC_TREE_SCHEMA)\n",
    "    f.write(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8495c5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the schema files to create tables using SQL\n",
    "with engine.connect() as connection:\n",
    "    \n",
    "    connection.execute(\"DROP TABLE IF EXISTS nyc_zip_codes, complaints_311, trees, rents CASCADE\") # if table already exists\n",
    "    \n",
    "    connection.execute(ZIPCODE_SCHEMA)\n",
    "    connection.execute(NYC_311_SCHEMA)\n",
    "    connection.execute(NYC_TREE_SCHEMA)\n",
    "    connection.execute(ZILLOW_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3169f726",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f4f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to sql table\n",
    "df_zillow_data.to_sql('rents', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "# GeoDataFrame data into a PostGIS-enabled PostgreSQL table\n",
    "geodf_311_data.to_postgis('complaints', con=engine, if_exists='replace', index=False)\n",
    "geodf_zipcode_data.to_postgis('zipcodes', con=engine, if_exists='replace', index=False)\n",
    "geodf_tree_data.to_postgis('trees', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02abdef3",
   "metadata": {},
   "source": [
    "# Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461487ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query: str, outfile: str):\n",
    "    with open(outfile, \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92337e74",
   "metadata": {},
   "source": [
    "## Query 1: Which area might be more calm to live in?\n",
    "Between October 1st, 2022 and September 30th, 2023 (inclusive), find the number of 311 complaints per zip code. \n",
    "\n",
    "The query result should have two columns, one row per zip code, with the number of complaints in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c447be",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = QUERY_DIR / \"num_complaints_by_zipcode\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT incident_zip, COUNT(*) AS complaints_count\n",
    "FROM complaints\n",
    "WHERE\n",
    "    created_date BETWEEN '2022-10-01T00:00:00.000' AND '2023-09-30T23:59:59.999'\n",
    "GROUP BY incident_zip\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b009002",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a30409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the query\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_1)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcdc624",
   "metadata": {},
   "source": [
    "## Query 2: Where has the most greenery?\n",
    "Using just the trees table, which 10 zip codes have the most trees?\n",
    "\n",
    "The query result should have two columns, 10 rows. The rows should be sorted by the total number of trees, descending.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = QUERY_DIR / \"top_10_zipcodes_with_most_trees\"\n",
    "\n",
    "# table column name is the same as dataframe, not schema!!!\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT zipcode, COUNT(*) AS total_trees\n",
    "FROM trees\n",
    "GROUP BY zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d084b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the query\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_2)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b515e",
   "metadata": {},
   "source": [
    "## Query 3: Can I afford a place in the areas with the most trees?\n",
    "Of the 10 zip codes with the most trees, for the month of August 2023, what is the average rent by zip code?\n",
    "\n",
    "The query should have a JOIN statement. The query result should have two columns (not three) and 10 rows. The rows should be sorted by the total number of trees, descending. “Humanize” the rent numbers, meaning format the results as 2,879.58 instead of 2879.575128. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = QUERY_DIR / \"avg_rent_for_top_10_zipcodes_with_most_trees\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "WITH top10_zipcodes AS (\n",
    "    SELECT zipcode, COUNT(*) AS total_trees\n",
    "    FROM trees\n",
    "    GROUP BY zipcode\n",
    "    ORDER BY total_trees DESC\n",
    "    LIMIT 10\n",
    ")\n",
    "\n",
    "SELECT t.zipcode, ROUND(AVG(r.rent_amount)::numeric, 2) AS average_rent\n",
    "FROM rents r\n",
    "JOIN trees t ON t.zipcode = r.rent_zip::text\n",
    "WHERE DATE_PART('month', r.rent_date) = 8\n",
    "    AND DATE_PART('year', r.rent_date) = 2023\n",
    "    AND r.rent_zip::text IN (SELECT zipcode FROM top10_zipcodes)\n",
    "GROUP BY t.zipcode\n",
    "ORDER BY (SELECT total_trees FROM top10_zipcodes WHERE zipcode = t.zipcode) DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the query\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_3)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c73871",
   "metadata": {},
   "source": [
    "## Query 4: Could there be a correlation between an area’s rent, the number of its trees, and the number of 311 complaints?\n",
    "For the month of January 2023, return the 5 zip codes with the lowest average rent, and 5 zipcodes of the highest average rent, and include the tree count and complaint count for each zip code by using JOIN statements.\n",
    "\n",
    "The query result should have 4 columns (zip code, average rent, tree count, and complaint count) and 10 rows: five with the highest average rent, and five with the lowest average rent. “Humanize” the rent numbers, meaning format the results as 2,879.58 instead of 2879.575128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = QUERY_DIR / \"rent_trees_complaints_correlation\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH RentData AS (\n",
    "    SELECT CAST(r.rent_zip AS TEXT) AS zipcode, \n",
    "           CAST(AVG(r.rent_amount) AS DECIMAL(10, 2)) AS average_rent\n",
    "    FROM rents r\n",
    "    WHERE DATE_PART('month', r.rent_date) = 1\n",
    "      AND DATE_PART('year', r.rent_date) = 2023\n",
    "    GROUP BY r.rent_zip\n",
    "),\n",
    "TreeData AS (\n",
    "    SELECT zipcode, COUNT(*) AS tree_count\n",
    "    FROM trees\n",
    "    GROUP BY zipcode\n",
    "),\n",
    "ComplaintData AS (\n",
    "    SELECT incident_zip AS zipcode, COUNT(*) AS complaint_count\n",
    "    FROM complaints\n",
    "    WHERE DATE_PART('month', created_date) = 1\n",
    "      AND DATE_PART('year', created_date) = 2023\n",
    "    GROUP BY incident_zip\n",
    "),\n",
    "LowestRent AS (\n",
    "    SELECT * FROM RentData\n",
    "    ORDER BY average_rent ASC\n",
    "    LIMIT 5\n",
    "),\n",
    "HighestRent AS (\n",
    "    SELECT * FROM RentData\n",
    "    ORDER BY average_rent DESC\n",
    "    LIMIT 5\n",
    ")\n",
    "SELECT lr.zipcode,\n",
    "       lr.average_rent AS formatted_rent,\n",
    "       COALESCE(td.tree_count, 0) AS tree_count,\n",
    "       COALESCE(cd.complaint_count, 0) AS complaint_count\n",
    "FROM LowestRent lr\n",
    "LEFT JOIN TreeData td ON lr.zipcode = td.zipcode\n",
    "LEFT JOIN ComplaintData cd ON lr.zipcode = cd.zipcode\n",
    "UNION ALL\n",
    "SELECT hr.zipcode,\n",
    "       hr.average_rent AS formatted_rent,\n",
    "       COALESCE(td.tree_count, 0) AS tree_count,\n",
    "       COALESCE(cd.complaint_count, 0) AS complaint_count\n",
    "FROM HighestRent hr\n",
    "LEFT JOIN TreeData td ON hr.zipcode = td.zipcode\n",
    "LEFT JOIN ComplaintData cd ON hr.zipcode = cd.zipcode;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa45c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the query\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_4)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a7d21",
   "metadata": {},
   "source": [
    "## Query 5: Where has the most greenery (take 2)?\n",
    "Rewrite Query 2 to use both the trees table and the zipcodes table. Join both tables where the coordinate point of the tree is inside the polygon boundary of the zipcode as defined in the zipcode table.\n",
    "\n",
    "The query should have a JOIN statement. The query results should match exactly the results of Query 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50c370",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = QUERY_DIR / \"top_10_zipcodes_with_most_trees_by_geometry\"\n",
    "\n",
    "QUERY_5 = \"\"\"\n",
    "SELECT z.zipcode, COUNT(*) AS total_trees\n",
    "FROM zipcodes z\n",
    "JOIN trees AS t ON ST_Contains(z.geometry, t.geometry)\n",
    "GROUP BY z.zipcode\n",
    "ORDER BY total_trees DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e46ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the query\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_5)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad142b",
   "metadata": {},
   "source": [
    "## Query 6: What is the immediate area like?\n",
    "Using the following coordinate pair on campus, which trees are within ½ mile radius of this point?\n",
    "Latitude: 40.80737875669467, Longitude: -73.96253174434912\n",
    "\n",
    "The result should have 5 columns (ID, species, health, status, and coordinate location of each tree).\n",
    "\n",
    "You may use regular Python to help construct the geometric object needed for setting the radius in the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_latitude = 40.80737875669467\n",
    "target_longitude = -73.96253174434912\n",
    "\n",
    "target_point = Point(target_longitude, target_latitude)\n",
    "\n",
    "# Create a circle with a radius of 0.5 miles around the target location\n",
    "radius = 0.5  # in miles\n",
    "circle_buffer = target_point.buffer(radius / 69)  # Assuming 1 degree of latitude is approximately 69 miles\n",
    "\n",
    "gdf_circle = gpd.GeoDataFrame(geometry=[circle_buffer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e0f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = QUERY_DIR / \"trees_within_coordinate_pair\"\n",
    "\n",
    "QUERY_6 = f\"\"\"\n",
    "SELECT tree_id, spc_common, health, status, ST_AsText(geometry) AS coordinate_location\n",
    "FROM trees\n",
    "WHERE ST_Intersects(geometry, ST_GeomFromText('{circle_buffer.wkt}', 4326))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba375b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8307549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the query\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(QUERY_5)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1024df9a",
   "metadata": {},
   "source": [
    "# Part 4: Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b467ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render graphics directly in the notebook without having to call plt.show\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-dark\")  # Choose a color palett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select data\n",
    "query1 = 'SELECT * FROM rents'\n",
    "query2 = 'SELECT * FROM complaints'\n",
    "query3 = 'SELECT * FROM trees'\n",
    "query4 = 'SELECT * FROM zipcodes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data into pandas DataFrame and geopandas GeoDataFrame\n",
    "rent_data = pd.read_sql(query1, engine)\n",
    "\n",
    "complaint_data = gpd.read_postgis(query2, con=engine, geom_col='geometry')\n",
    "tree_data = gpd.read_postgis(query3, con=engine, geom_col='geometry')\n",
    "zipcode_data = gpd.read_postgis(query4, con=engine, geom_col='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4d2bc",
   "metadata": {},
   "source": [
    "## Visualization 1: What can I expect to put up with in NYC?\n",
    "First, find the top 3 complaint types for October 1st, 2022 to September 30th, 2023 (inclusive). \n",
    "\n",
    "Then, create an appropriate visualization for the number of complaints per day over $timeframe for those complaint types.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data selection - skipped for now\n",
    "def get_data_for_visual_1() -> pd.DataFrame:\n",
    "    \"\"\"Get the dataframe needed for visualization 1.\"\"\"\n",
    "    \n",
    "    # Set time range\n",
    "    start_date = pd.Timestamp('2022-10-01')\n",
    "    end_date = pd.Timestamp('2023-09-30')\n",
    "    # Select data within the time range\n",
    "    complaint_data_filtered = complaint_data.loc[(complaint_data['created_date'] >= start_date) \n",
    "                              & (complaint_data['created_date'] <= end_date)]\n",
    "    # Select data of top 3 complaint types\n",
    "    top_3_types = complaint_data_filtered['complaint_type'].value_counts().nlargest(3).index.tolist()\n",
    "    df_top3 =  complaint_data[complaint_data['complaint_type'].isin(top_3_types)].copy()\n",
    "    # Group data by creation date\n",
    "    df_top3['created_date'] = pd.to_datetime(df_top3['created_date'])\n",
    "    df_top3_grouped = df_top3.groupby(df_top3['created_date'].dt.date)['incident_zip'].size().reset_index(name='count')\n",
    "    \n",
    "    return df_top3_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f524853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: use current data\n",
    "top_3_types = complaint_data['complaint_type'].value_counts().nlargest(3).index.tolist()\n",
    "df_top3 =  complaint_data[complaint_data['complaint_type'].isin(top_3_types)].copy()\n",
    "\n",
    "df_top3['created_date'] = pd.to_datetime(df_top3['created_date'])\n",
    "\n",
    "df_top3_grouped = df_top3.groupby(df_top3['created_date'].dt.date)['incident_zip'].size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cdf5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulization\n",
    "def top_3_complaint_types(df_top3_grouped: pd.DataFrame):\n",
    "    \"\"\"Create the plot 'Number of Complaints per Day for Top 3 Complaint Types'.\"\"\"\n",
    "    \n",
    "    df_top3_grouped.plot(kind='line', figsize=(10, 6))\n",
    "    plt.title('Number of Complaints per Day for Top 3 Complaint Types')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Complaints')\n",
    "    plt.legend(title='Complaint Type')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_complaint_types(df_top3_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337fa936",
   "metadata": {},
   "source": [
    "### Extra credit 1: animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27114c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Function to update the plot for each frame in the animation\n",
    "def update(frame: int):\n",
    "    \"\"\"\n",
    "    A Function for the animation\n",
    "    \n",
    "    Parameters:\n",
    "    frame(int): Frame number for the animation\n",
    "    \"\"\"\n",
    "    ax.clear()\n",
    "    ax.plot(df_top3_grouped.index[:frame+1], df_top3_grouped.values[:frame+1])\n",
    "    ax.set_title('Number of Complaints per Day')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Number of Complaints')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Create the animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(df_top3_grouped), interval=100, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e0c8e6",
   "metadata": {},
   "source": [
    "## Visualization 2: What are the most common complaints in the immediate area?¶\n",
    "Create a visualization that shows the number of complaints by complaint type for the top 10 complaints in zip code 10027 for October 1st, 2018 to September 30th, 2023 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d583a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data selection - skipped for now\n",
    "def get_data_for_visual_2() -> pd.Series:\n",
    "    \"\"\"Get the dataframe needed for visualization 2.\"\"\"\n",
    "    \n",
    "    # Set time range\n",
    "    start_date = pd.Timestamp('2018-10-01')\n",
    "    end_date = pd.Timestamp('2023-09-30')\n",
    "    # Select the data within the time range in zip code 10027 \n",
    "    df_zipcode_10027 = complaint_data.loc[(complaint_data['incident_zip'] == 10027.0) &\n",
    "                          (complaint_data['created_date'] >= start_date) &\n",
    "                          (complaint_data['created_date'] <= end_date)]\n",
    "    # Get the top 10 complaint types\n",
    "    df_top10 = complaint_data['complaint_type'].value_counts().nlargest(10)\n",
    "    \n",
    "    return df_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23411de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: use current data\n",
    "df_top10 = complaint_data['complaint_type'].value_counts().nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c47733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def top_10_complaint_types_10027(df_top10: pd.Series):\n",
    "    \"\"\"Greate the histogram of 'Top 10 Complaint Types in Zip Code 10027'.\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df_top10.plot(kind='bar', color='skyblue')\n",
    "    \n",
    "    plt.xlabel('Complaint Type')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Top 10 Complaint Types in Zip Code 10027')\n",
    "    \n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385372b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_complaint_types_10027(df_top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb36c9",
   "metadata": {},
   "source": [
    "## Visualization 3: Is there any correlation between rent, trees, and complaints at all?\n",
    "Between January 1st, 2015 and September 30th, 2023 (inclusive), create a visualization using 2 subplots that share the x-axis where one subplot shows rent compared to the number of trees by zip code, and the other subplot shows rent compared to the number of complaints by zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece23ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data selection - skipped for now\n",
    "def get_data_for_visual_3() -> pd.DataFrame:\n",
    "    \"\"\"Get the dataframe needed for visualization 3.\"\"\"\n",
    "    \n",
    "    # Select the rent data within time range\n",
    "    rent_data_filtered = rent_data[(rent_data['rent_date'] >= '2015-01-01') \n",
    "                                   & (rent_data['rent_date'] <= '2023-09-30')]\n",
    "    # Match column data type\n",
    "    rent_data_filtered['rent_zip'] = rent_data_filtered['rent_zip'].astype(str) \n",
    "    \n",
    "    # Select the complaint data within time range\n",
    "    complaint_data_filtered = complaint_data[(complaint_data['created_date'] >= '2015-01-01') \n",
    "                                             & (complaint_data['created_date'] <= '2023-09-30')]\n",
    "    # Group complaints and trees by zipcode\n",
    "    complaint_by_zip = complaint_data_filtered.groupby('incident_zip').size().reset_index(name='num_complaints')\n",
    "    trees_by_zip = tree_data.groupby('zipcode').size().reset_index(name='num_trees')\n",
    "    # Merge filtered data frame\n",
    "    merged_data = rent_data_filtered.merge(trees_by_zip, left_on='rent_zip', right_on='zipcode', how='inner')\n",
    "    merged_data = merged_data.merge(complaint_by_zip, left_on='rent_zip', right_on='incident_zip', how='inner')\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test:\n",
    "# rent_data_filtered = rent_data[(rent_data['rent_date'] >= '2015-01-01') & (rent_data['rent_date'] <= '2023-09-30')]\n",
    "rent_data['rent_zip'] = rent_data['rent_zip'].astype(str) # match column data type\n",
    "\n",
    "# complaint_data_filtered = complaint_data[(complaint_data['created_date'] >= '2015-01-01') & (complaint_data['created_date'] <= '2023-09-30')]\n",
    "complaint_by_zip = complaint_data.groupby('incident_zip').size().reset_index(name='num_complaints')\n",
    "\n",
    "trees_by_zip = tree_data.groupby('zipcode').size().reset_index(name='num_trees')\n",
    "\n",
    "merged_data = rent_data.merge(trees_by_zip, left_on='rent_zip', right_on='zipcode', how='inner')\n",
    "merged_data = merged_data.merge(complaint_by_zip, left_on='rent_zip', right_on='incident_zip', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def rent_trees_complaints_correlation(merged_data: pd.DataFrame):\n",
    "    \"\"\"Create the 2 subplots on the correlation between rent, trees, and complaints.\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "    \n",
    "    ax1.scatter(merged_data['rent_amount'], merged_data['num_trees'])\n",
    "    ax1.set_ylabel('Number of Trees')\n",
    "    \n",
    "    ax2.scatter(merged_data['rent_amount'], merged_data['num_complaints'])\n",
    "    ax2.set_ylabel('Number of Complaints')\n",
    "    \n",
    "    plt.xlabel('Rent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_trees_complaints_correlation(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22668664",
   "metadata": {},
   "source": [
    "## Visualization 4: If I can afford more in rent, will there be fewer issues & complaints?\n",
    "Create a boxplot, where the x-axis is average rent in September 2023, separated into $1000 bins (i.e. $0-1000, $1001-2000, etc), and the y-axis is the number of 311 complaints observed in each zip code between October 1, 2022 (inclusive) to September 30, 2023 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data selection - skipped for now\n",
    "def get_data_for_visual_4() -> pd.DataFrame:\n",
    "    \"\"\"Get the dataframe needed for visualization 4.\"\"\"\n",
    "    \n",
    "    # Define bin ranges and labels for rent amounts\n",
    "    bins = [0, 1000, 2000, 3000, 4000, np.inf]\n",
    "    bin_labels = ['0-1000', '1001-2000', '2001-3000', '3001-4000', '4001+']\n",
    "    \n",
    "    # Match column data type\n",
    "    rent_data['rent_zip'] = rent_data['rent_zip'].astype(str)\n",
    "    # Select data within the time range and divide into bins\n",
    "    rent_data['rent_bin'] = pd.cut(rent_data['rent_amount'], bins=bins, labels=bin_labels)\n",
    "    rent_data_sept_2023 = rent_data[(rent_data['rent_date'] <= '2023-09-30')\n",
    "                                    & (rent_data['rent_date'] >= '2023-09-01')]\n",
    "    average_rent_by_zipcode = rent_data_sept_2023.groupby('rent_zip')['rent_amount'].mean().reset_index()\n",
    "    average_rent_by_zipcode.columns = ['rent_zip', 'average_rent']\n",
    "    average_rent_by_zipcode['rent_bin'] = pd.cut(average_rent_by_zipcode['average_rent'], bins=bins, labels=bin_labels)\n",
    "    \n",
    "    # Filter and groupby complaint data\n",
    "    complaints_data_filtered = complaint_data[(complaint_data['created_date'] >= '2022-10-01') \n",
    "                                              & (complaint_data['created_date'] <= '2023-09-30')]\n",
    "    complaints_by_zip = complaints_data_filtered.groupby('incident_zip').size().reset_index(name='num_complaints')\n",
    "    \n",
    "    # Merge data\n",
    "    merged_data = rent_data_sept_2023.merge(complaints_by_zip, left_on='rent_zip', right_on='incident_zip', how='inner')\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test:   \n",
    "#rent_data_sept_2023 = rent_data[(rent_data['rent_date'] >= '2023-09-01') & (rent_data['rent_date'] <= '2023-09-30')]\n",
    "bins = [0, 1000, 2000, 3000, 4000, np.inf]\n",
    "bin_labels = ['0-1000', '1001-2000', '2001-3000', '3001-4000', '4001+']\n",
    "\n",
    "rent_data['rent_zip'] = rent_data['rent_zip'].astype(str) # match column data type\n",
    "\n",
    "# Select data within the time range and divide into bins\n",
    "rent_data_sept_2023 = rent_data[(rent_data['rent_date'] <= '2023-09-30')\n",
    "                                & (rent_data['rent_date'] >= '2023-09-01')].groupby('rent_zip')['rent_amount'].mean().reset_index()\n",
    "\n",
    "average_rent_by_zipcode = rent_data_sept_2023.groupby('rent_zip')['rent_amount'].mean().reset_index()\n",
    "average_rent_by_zipcode.columns = ['rent_zip', 'average_rent']\n",
    "average_rent_by_zipcode['rent_bin'] = pd.cut(average_rent_by_zipcode['average_rent'], bins=bins, labels=bin_labels)\n",
    "\n",
    "#complaints_data_filtered = complaints_data[(complaints_data['created_date'] >= '2022-10-01') & (complaints_data['created_date'] <= '2023-09-30')]\n",
    "\n",
    "complaints_by_zip = complaint_data.groupby('incident_zip').size().reset_index(name='num_complaints')\n",
    "\n",
    "merged_data = average_rent_by_zipcode.merge(complaints_by_zip, left_on='rent_zip', right_on='incident_zip', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71258a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visulization\n",
    "def rent_complaints_correlation(merged_data: pd.DataFrame):\n",
    "    \"\"\"Create the plot 'Boxplot of Rent vs. 311 Complaints'.\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot([merged_data[merged_data['rent_bin'] == label]['num_complaints'] for label in bin_labels], labels=bin_labels)\n",
    "    plt.xlabel('Average Rent in September 2023 (Bins)')\n",
    "    plt.ylabel('Number of 311 Complaints (Oct 1, 2022 - Sep 30, 2023)')\n",
    "    plt.title('Boxplot of Rent vs. 311 Complaints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rent_complaints_correlation(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45eef8",
   "metadata": {},
   "source": [
    "## Visualization 5: Where were the recent 311 incidents reported from in the immediate area?\n",
    "Create a geospatial plot of the coordinates of reported 311 incidents that happened between January 1st, 2023 and September 30th, 2023 (inclusive) within a 1 kilometer radius of the same coordinate from Query 6 in Part 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data selection - skipped for now\n",
    "def get_data_for_visual_5() -> gpd.GeoDataFrame:\n",
    "    \"\"\"Get the dataframe needed for visualization 5.\"\"\"\n",
    "    # Select data within time range\n",
    "    complaints_data_filtered = complaint_data[(complaint_data['created_date'] >= '2023-01-01') \n",
    "                                              & (complaint_data['created_date'] <= '2023-09-30')]\n",
    "    \n",
    "    # Create a Point geometry of the target location\n",
    "    target_latitude = 40.80737875669467\n",
    "    target_longitude = -73.96253174434912\n",
    "    target_point = Point(target_longitude, target_latitude)\n",
    "    \n",
    "    # Calculate distance between incidents and the target location\n",
    "    complaints_data_filtered['distance_to_target'] = complaints_data_filtered['geometry'].distance(target_point)\n",
    "    \n",
    "    # Filter incidents within a 1-kilometer radius of the target location\n",
    "    df_incidents_within_radius = complaints_data_filtered[complaints_data_filtered['distance_to_target'] <= 1000]  # Distance in meters (1 kilometer = 1000 meters)\n",
    "    \n",
    "    return df_incidents_within_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb4822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### test:\n",
    "\n",
    "# Create a Point geometry\n",
    "target_latitude = 40.80737875669467\n",
    "target_longitude = -73.96253174434912\n",
    "\n",
    "target_point = Point(target_longitude, target_latitude)\n",
    "\n",
    "# Calculate distance between incidents and the target location\n",
    "complaint_data['distance_to_target'] = complaint_data['geometry'].distance(target_point)\n",
    "\n",
    "# Filter incidents within a 1-kilometer radius of the target location\n",
    "df_incidents_within_radius = complaint_data[complaint_data['distance_to_target'] <= 10000]  # Distance in meters (1 kilometer = 1000 meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cceefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def incidents_within_radius(df_incidents_within_radius: gpd.GeoDataFrame):\n",
    "    \"\"\"Greate the plot '311 Incidents within 1km Radius'.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    \n",
    "    world.plot(ax=ax, color='lightgrey')\n",
    "    df_incidents_within_radius.plot(ax=ax, markersize=10, color='red', marker='o', label='Incidents within 1km radius')\n",
    "    \n",
    "    ax.legend()\n",
    "    plt.title('311 Incidents within 1km Radius')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2afb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "incidents_within_radius(df_incidents_within_radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a11e0c",
   "metadata": {},
   "source": [
    "## Visualization 6: Are areas trying to improve the amount of trees in the neighborhood?\n",
    "Create a geospatial plot of two sets of data: the coordinates of trees in NYC, and the coordinates of \"New Tree Request\" 311 complaint types that were made from October 1st, 2018 to September 30th, 2023 (inclusive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb08e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data selection - skipped for now\n",
    "def get_data_for_visual_6() -> gpd.GeoDataFrame:\n",
    "    \"\"\"Get the dataframe needed for visualization 6.\"\"\"\n",
    "    \n",
    "    # Select \"New Tree Request\" complaints within the time range\n",
    "    new_tree_requests = complaint_data[\n",
    "        (complaint_data['complaint_type'] == 'New Tree Request') \n",
    "        & (complaint_data['created_date'] >= '2018-10-01') \n",
    "        & (complaint_data['created_date'] <= '2023-09-30')\n",
    "]\n",
    "    return new_tree_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tree_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e225a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trees_and_new_trees_request(tree_data: gpd.GeoDataFrame, new_tree_requests: gpd.GeoDataFrame):\n",
    "    \"\"\"Create the plot 'Trees and New Tree Requests'.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    tree_data.plot(ax=ax, color='green', alpha=0.7, label='Trees')\n",
    "    new_tree_requests.plot(ax=ax, color='blue', alpha=0.7, label='New Tree Requests')\n",
    "    \n",
    "    plt.title('Trees and New Tree Requests')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dceee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test:\n",
    "trees_and_new_trees_request(tree_data, complaint_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a45d3",
   "metadata": {},
   "source": [
    "## Extra Credit-2 UnitTests\n",
    "\n",
    "Define at least one unit test for every function and class method you’ve defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPartOne(unittest.TestCase):  \n",
    "    \n",
    "    def test_download_nyc_geojson_data(self) -> None:  \n",
    "        url = \"https://data.cityofnewyork.us/resource/erm2-nwe9.geojson?$$app_token=RbFfvU4T8a7C7rDHaA9eqAkvZ&$limit=1000\"\n",
    "        file_name = 'complaints_(1000)'\n",
    "        download_nyc_geojson_data(url, file_name, force)\n",
    "        expected_file = 'complaints.geojson'\n",
    "        file_exists = os.path.isfile(expected_file)\n",
    "        self.assertTrue(file_exists, f\"Didn't successfully download '{expected_file}'.\")       \n",
    "\n",
    "    def test_download_and_clean_311_data(self) -> None:\n",
    "        result = download_and_clean_311_data()\n",
    "        self.assertTrue(isinstance(result, gpd.GeoDataFrame))\n",
    "        \n",
    "    def test_download_and_clean_tree_data(self) -> None:\n",
    "        result = download_and_clean_tree_data()\n",
    "        expected_columns = ['tree_id', 'zipcode', 'spc_common', 'health', 'status','geometry']]\n",
    "        for column in expected_columns:\n",
    "            self.assertIn(column, result.columns)\n",
    "            \n",
    "    def test_load_and_clean_zipcodes(self) -> None:\n",
    "        result = load_and_clean_zipcodes('data/zipcodes/nyc_zipcodes.shp')\n",
    "        self.assertTrue(isinstance(result, gpd.GeoDataFrame))\n",
    "        \n",
    "    def test_load_and_clean_zillow_data(self) -> None:\n",
    "        result = load_and_clean_zillow_data('data/zillow_rent_data.csv')\n",
    "        self.assertTrue(isinstance(result, pd.DataFrame))\n",
    "        \n",
    "    def test_load_all_data(self) -> None:\n",
    "        a, b, c, d = load_all_data()\n",
    "        self.assertTrue(isinstance(a, gpd.GeoDataFrame))\n",
    "        self.assertTrue(isinstance(b, gpd.GeoDataFrame))\n",
    "        self.assertTrue(isinstance(c, gpd.GeoDataFrame))\n",
    "        self.assertTrue(isinstance(d, pd.DataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e239ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPartTwo(unittest.TestCase):  \n",
    "    def test_write_query_to_file(self) -> None:\n",
    "        \n",
    "        test_file = 'try.sql'\n",
    "        write_query_to_file(\n",
    "            \"CREATE TABLE test_table (id INT, column_one VARCHAR(255))\",\n",
    "            test_file)\n",
    "        \n",
    "        self.assertTrue(os.path.isfile(test_file), f\"Did not create file '{test_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e931fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get thorough examination and detailed debugging during test execution\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], verbosity=3, exit = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
